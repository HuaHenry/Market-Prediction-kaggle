{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":14861981,"sourceType":"competition"},{"sourceId":14125080,"sourceType":"datasetVersion","datasetId":8999557}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional  # ✅ 加上 Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport kaggle_evaluation.default_inference_server\n\n\n# ==================== DATA PREPROCESSING ====================\ndef preprocessing(data, typ):\n    \"\"\"\n    Preprocess the data by selecting features and handling missing values\n    \"\"\"\n    main_features = [\n        'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10',\n        'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20',\n        'I2',\n        'P8', 'P9', 'P10', 'P12', 'P13',\n        'S1', 'S2', 'S5'\n    ]\n    \n    # Convert to numeric safely\n    for col in data.columns:\n        if col not in ['date_id', 'forward_returns', 'is_scored']:\n            if data[col].dtype == 'object':\n                data[col] = pd.to_numeric(data[col], errors='coerce')\n    \n    available_features = [f for f in main_features if f in data.columns]\n    \n    if typ == \"train\":\n        data = data[available_features + [\"forward_returns\"]]\n    else:\n        data = data[available_features]\n    \n    data = data.fillna(0)\n    return data\n\n\n# ==================== SEQUENCE CREATION ====================\ndef create_sequences(X, y, timesteps=1):\n    \"\"\"\n    Convert tabular data into sequences for LSTM/BiLSTM input\n    \"\"\"\n    Xs, ys = [], []\n    for i in range(len(X) - timesteps):\n        Xs.append(X[i:(i + timesteps)])\n        ys.append(y[i + timesteps])\n    return np.array(Xs), np.array(ys)\n\n\n# ==================== BiLSTM MODEL TRAINING ====================\ndef train_lstm_model(X_train, y_train, X_val, y_val, timesteps=1):\n    \"\"\"\n    Train a Bidirectional LSTM regression model\n    \"\"\"\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n    \n    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train.values, timesteps)\n    X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val.values, timesteps)\n    \n    n_features = X_train.shape[1]\n\n    model = Sequential([\n        Bidirectional(\n            LSTM(128, return_sequences=False),\n            input_shape=(timesteps, n_features)\n        ),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(1)\n    ])\n    \n    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n    \n    print(\"Training BiLSTM model...\")\n    history = model.fit(\n        X_train_seq, y_train_seq,\n        validation_data=(X_val_seq, y_val_seq),\n        epochs=30,\n        batch_size=64,\n        verbose=1\n    )\n    print(\"BiLSTM model trained successfully!\")\n    \n    return model, scaler\n\n\n# ==================== GLOBAL MODEL STORAGE ====================\nTRAINED_MODELS = {}\n\n\n# ==================== PREDICTION FUNCTION ====================\ndef predict(test_data):\n    \"\"\"\n    Use trained BiLSTM model to predict test sample\n    (robust version with feature alignment and safety)\n    \"\"\"\n    if isinstance(test_data, dict):\n        df = pd.DataFrame([test_data])\n    else:\n        df = pd.DataFrame(test_data)\n    \n    df_processed = preprocessing(df, \"test\")\n    \n    model = TRAINED_MODELS['model_3']\n    scaler = TRAINED_MODELS['scaler']\n    timesteps = TRAINED_MODELS['timesteps']\n    expected_features = TRAINED_MODELS.get('features', df_processed.columns.tolist())\n    \n    # 1️⃣ 补齐缺失列\n    for col in expected_features:\n        if col not in df_processed.columns:\n            df_processed[col] = 0.0\n    \n    # 2️⃣ 保证顺序一致\n    df_processed = df_processed[expected_features]\n    \n    # 3️⃣ 防空输入\n    if df_processed.shape[0] == 0:\n        return 0.0\n    \n    # 4️⃣ 转换成 numpy\n    X_test = df_processed.values.astype(float)\n    \n    # 5️⃣ 标准化（防止 feature name 警告）\n    try:\n        X_test_scaled = scaler.transform(X_test)\n    except Exception:\n        # 如果 scaler 无法 transform（无特征名等），重新拟合一次以兼容\n        scaler.fit(X_test)\n        X_test_scaled = scaler.transform(X_test)\n    \n    # 6️⃣ 形状调整：注意这里 timesteps 一般是 1（逐行预测）\n    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], timesteps, X_test_scaled.shape[1]))\n    \n    # 7️⃣ 预测\n    pred = model.predict(X_test_scaled)\n    \n    return float(pred[0][0]) if pred.size > 0 else 0.0\n\n\n# ==================== MAIN EXECUTION ====================\nif __name__ == \"__main__\":\n    print(\"=\" * 60)\n    print(\"Hull Tactical Market Prediction - BiLSTM Solution\")\n    print(\"=\" * 60)\n    \n    # ⭐ 修改点1：训练数据改为读取你本地“已经处理好”的 CSV =====================\n    print(\"\\nLoading training data from LOCAL processed CSV...\")\n    # TODO: 把下面路径改成你自己本地的路径\n    LOCAL_TRAIN_PATH = \"/kaggle/input/data121/train_filtered_threshold_0p01.csv\"\n    train = pd.read_csv(LOCAL_TRAIN_PATH)\n    print(f\"Local processed train shape: {train.shape}\")\n    \n    # 做一个小检查：必须有 forward_returns 列\n    if \"forward_returns\" not in train.columns:\n        raise ValueError(\n            \"本地训练数据中必须包含目标列 'forward_returns'，\"\n            \"请确认你的 CSV 列名。\"\n        )\n    # ====================================================================\n    \n    # ⭐ 修改点2：不再对训练数据调用 preprocessing ==========================\n    # 原来代码是：\n    # print(\"\\nPreprocessing data...\")\n    # train = preprocessing(train, 'train')\n    # 现在本地 train 已经是你处理好的数据，就不需要再预处理了\n    # ====================================================================\n    \n    # （可选）如果你仍然在 Kaggle 环境跑，并想打印一下官方 test 的形状：\n    try:\n        test = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/test.csv')\n        print(f\"Official test shape (for reference): {test.shape}\")\n    except Exception as e:\n        print(\"Warning: cannot load official Kaggle test.csv, error:\", e)\n    \n    # Split data\n    train_split, val_split = train_test_split(train, test_size=0.01, random_state=4)\n    X_train = train_split.drop(columns=[\"forward_returns\"])\n    y_train = train_split['forward_returns']\n    X_val = val_split.drop(columns=[\"forward_returns\"])\n    y_val = val_split['forward_returns']\n    \n    print(f\"Training samples: {len(X_train)}\")\n    print(f\"Validation samples: {len(X_val)}\")\n    \n    # Set LSTM time window\n    timesteps = 1  # 你之后如果需要多步时序建模，可以改成 >1\n    \n    # Train Model 3 (BiLSTM)\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Training Model 3 - Bidirectional LSTM\")\n    print(\"=\" * 60)\n    model_3, scaler = train_lstm_model(X_train, y_train, X_val, y_val, timesteps=timesteps)\n    \n    # Evaluate\n    X_val_scaled = scaler.transform(X_val)\n    X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val.values, timesteps)\n    val_pred = model_3.predict(X_val_seq)\n    val_rmse = np.sqrt(np.mean((y_val_seq - val_pred.flatten()) ** 2))\n    print(f\"\\nValidation RMSE: {val_rmse:.6f}\")\n    \n    # Save models and features\n    TRAINED_MODELS['model_3'] = model_3\n    TRAINED_MODELS['scaler'] = scaler\n    TRAINED_MODELS['timesteps'] = timesteps\n    TRAINED_MODELS['features'] = list(X_train.columns)\n    \n    # Setup inference server\n    print(\"\\n\" + \"=\" * 60)\n    print(\"Setting up inference server\")\n    print(\"=\" * 60)\n    \n    inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n    \n    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n        print(\"Running in competition mode...\")\n        inference_server.serve()\n    else:\n        print(\"Running local inference...\")\n        # 这里仍假设你在 Kaggle 环境下，官方数据目录不变\n        inference_server.run_local_gateway(('/kaggle/input/hull-tactical-market-prediction/',))\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"Execution completed!\")\n    print(\"=\" * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T10:42:50.371396Z","iopub.execute_input":"2025-12-12T10:42:50.371998Z","iopub.status.idle":"2025-12-12T10:43:23.039573Z","shell.execute_reply.started":"2025-12-12T10:42:50.371971Z","shell.execute_reply":"2025-12-12T10:43:23.038817Z"}},"outputs":[{"name":"stdout","text":"============================================================\nHull Tactical Market Prediction - BiLSTM Solution\n============================================================\n\nLoading training data from LOCAL processed CSV...\nLocal processed train shape: (8014, 86)\nOfficial test shape (for reference): (10, 99)\nTraining samples: 7933\nValidation samples: 81\n\n============================================================\nTraining Model 3 - Bidirectional LSTM\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"2025-12-12 10:42:50.748925: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Training BiLSTM model...\nEpoch 1/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0118 - val_loss: 4.6576e-04\nEpoch 2/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 2.2361e-04\nEpoch 3/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.4315e-04 - val_loss: 1.5125e-04\nEpoch 4/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8890e-04 - val_loss: 1.3347e-04\nEpoch 5/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9290e-04 - val_loss: 1.2263e-04\nEpoch 6/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6167e-04 - val_loss: 1.2136e-04\nEpoch 7/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4893e-04 - val_loss: 1.1867e-04\nEpoch 8/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3997e-04 - val_loss: 1.1803e-04\nEpoch 9/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3066e-04 - val_loss: 1.1712e-04\nEpoch 10/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2844e-04 - val_loss: 1.1717e-04\nEpoch 11/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2188e-04 - val_loss: 1.1698e-04\nEpoch 12/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2345e-04 - val_loss: 1.1752e-04\nEpoch 13/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2532e-04 - val_loss: 1.1653e-04\nEpoch 14/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2418e-04 - val_loss: 1.1772e-04\nEpoch 15/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1731e-04 - val_loss: 1.1900e-04\nEpoch 16/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2133e-04 - val_loss: 1.1848e-04\nEpoch 17/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2292e-04 - val_loss: 1.1786e-04\nEpoch 18/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2059e-04 - val_loss: 1.1890e-04\nEpoch 19/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1854e-04 - val_loss: 1.1837e-04\nEpoch 20/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1824e-04 - val_loss: 1.1579e-04\nEpoch 21/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2443e-04 - val_loss: 1.2013e-04\nEpoch 22/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1664e-04 - val_loss: 1.1800e-04\nEpoch 23/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1730e-04 - val_loss: 1.1630e-04\nEpoch 24/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1474e-04 - val_loss: 1.1852e-04\nEpoch 25/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1929e-04 - val_loss: 1.1683e-04\nEpoch 26/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1504e-04 - val_loss: 1.1800e-04\nEpoch 27/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2301e-04 - val_loss: 1.1783e-04\nEpoch 28/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1874e-04 - val_loss: 1.1814e-04\nEpoch 29/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1077e-04 - val_loss: 1.1845e-04\nEpoch 30/30\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1827e-04 - val_loss: 1.1862e-04\nBiLSTM model trained successfully!\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step\n\nValidation RMSE: 0.010891\n\n============================================================\nSetting up inference server\n============================================================\nRunning local inference...\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n\n============================================================\nExecution completed!\n============================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}